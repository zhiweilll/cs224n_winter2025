{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b505c25a",
   "metadata": {},
   "source": [
    "## Understanding `nn.Embedding` - Initialization vs. Usage\n",
    "\n",
    "**Confusion:from `1(d): nmt_model.py`** \n",
    "I thought when calling `self.model_embeddings.source(source_padded)`, the input should be `embed_size` and `vocab` (the parameters used to define `ModelEmbeddings`).\n",
    "\n",
    "**Resolution:** There are two distinct phases:\n",
    "\n",
    "**Creating vs. Using an `nn.Embedding` layer:**\n",
    "\n",
    "| Stage | What happens | Parameters |\n",
    "|-------|--------------|------------|\n",
    "| **Creation** (`__init__`) | Define the embedding layer (set up the lookup table) | `embed_size`, `vocab` — used to specify vocabulary size and embedding dimension |\n",
    "| **Usage** (forward pass) | Pass input data through the layer to get output | `source_padded` — an `IntTensor` or `LongTensor` containing word indices |\n",
    "\n",
    "**In code:**\n",
    "- `self.model_embeddings = ModelEmbeddings(embed_size, vocab)` → Creates the embedding layers with the specified configuration\n",
    "- `self.model_embeddings.source(source_padded)` → Uses the layer to convert word indices into word vectors\n",
    "\n",
    "**Think of it like a dictionary:**\n",
    "- **Creation**: Build a dictionary with N entries, each entry is a vector of dimension E\n",
    "- **Usage**: Look up words by their indices to retrieve their corresponding vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6ff30",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
